# Digit Recognizer Report
## Authors:
Jacob Wayne St Louis </br>
Abdurhman Adnan Bahour </br>
Jennifer Coburn </br>

Our group started by joining the Digit Recognizer competition, which introduces participants to computer vision and machine learning. The goal of the competition is to correctly identify handwritten digits using the MNIST dataset. The main evaluation metric is accuracy, which we hoped to achieve at a rate greater than 98%.

First, we followed the provided summary, which uses a Convolutional Neural Network (CNN) built with Keras. The tutorial is broken into three parts, which we followed step-for-step. We began by preparing the data: loading, normalizing, reshaping, and splitting. Then, we detected important patterns using filters for the CNN modeling, shrank the image data to make computations faster and prevent overfitting, and connected layers to make predictions. Next, we used the RMSprop optimizer, one epoch, and a batch size of 86. These parameters resulted in an accuracy score of 97.8%. We quickly realized our goal of an accuracy score greater than 98% by increasing the epochs from 1 to 30, as provided in the tutorial. Increasing the epochs to 30 gives the model more learning time, minimizing training loss and improving performance. Our final score was 99.24%, but we wanted to see if we could improve it further.

Next, following the successful accuracy score by adding 30 epochs, we swapped the RMSprop optimizer for Adam to take advantage of the dynamic learning rate, which we hope will help the model converge faster and imporove the score. Additionaly, we added a third CNN layer to capture more complex paterns in the data. This design resulted in a 94% accuracy. We suspect adding a 3rd CNN layer contributed to the decreased accuracy by overfitting to the training set. The last print statement at the 30th epoch showed a training loss of 0.4855 and a validation loss of 0.1850; the model performed better with validation data than with training data. This result means we could train for longer by increasing the number of epochs, increasing the batch size so the model sees more of the data at each step, or adding more layers to detect more patterns in the data.

Lastly, we tried three techniques to get a higher score. Within each of these, we increased the epoch to 60 or when 10 consecutive iterations occurred without improving the score, whichever occurred first. We also increased the batch size to 128 from 86. First, we attempted to implement batch normalization that could help normalize inputs, speed up training and improve accuracy. Our score dropped to 99.06% which implies it made it harder to train the model. Second, we tried adding a learning rate scheduler to the optimizer. The goal was to start fast but then fine-tune through a smaller learning rate, helping to avoid overshooting and improve accuracy. This technique allowed us to achieve a score of 99.43% which shows the scheduler had a significant postive impact. The third technique we tried was implementing enhanced data augmentation to increase the size and diversity of the dataset. This technique resulted in a significant drop in our score, down to 89.58%. Lastly, we attempted to combine these techniques but only scored 99.06%.

Overall, the tutorial achieved a significant initial accuracy score, allowing us to reach 99% by following all the provided steps and increasing the number of epochs. We were able to “beat” the tutorial by using a learning rate scheduler, which we believe allowed us to slightly improve our score by avoiding the overshooting that was most likely taking place when the rate scheduler was not in place.
